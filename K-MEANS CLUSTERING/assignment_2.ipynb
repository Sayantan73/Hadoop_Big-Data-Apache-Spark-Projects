{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing machine learning libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengimport modul yang dibutuhkan\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "#membuat session\n",
    "appName = \"Clustering di Apache Spark 2\"\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(appName) \\\n",
    ".config(\"spark.some.config.option\", \"some-value\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create customer data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------+--------+\n",
      "|Data|Fitur_X|Fitur_Y|Kelompok|\n",
      "+----+-------+-------+--------+\n",
      "|   1|      5|      8|       2|\n",
      "|   2|      5|      6|       2|\n",
      "|   3|      9|      3|       2|\n",
      "|   4|      1|      4|       1|\n",
      "|   5|      7|      8|       3|\n",
      "|   6|      1|      2|       1|\n",
      "|   7|      2|      2|       1|\n",
      "|   8|      9|      4|       3|\n",
      "|   9|      5|     10|       2|\n",
      "|  10|      6|      6|       2|\n",
      "+----+-------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# memuat data dari file ke DataFrame dengan infer skema\n",
    "latihan = spark.read.csv('latihan.csv', inferSchema=True, header=True)\n",
    "latihan.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "|Data|features  |\n",
      "+----+----------+\n",
      "|1   |[5.0,8.0] |\n",
      "|2   |[5.0,6.0] |\n",
      "|3   |[9.0,3.0] |\n",
      "|4   |[1.0,4.0] |\n",
      "|5   |[7.0,8.0] |\n",
      "|6   |[1.0,2.0] |\n",
      "|7   |[2.0,2.0] |\n",
      "|8   |[9.0,4.0] |\n",
      "|9   |[5.0,10.0]|\n",
      "|10  |[6.0,6.0] |\n",
      "+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# membuat assembler untuk mengubah fitur menjadi satu kolom fitur\n",
    "assembler = VectorAssembler(inputCols = [\"Fitur_X\", \"Fitur_Y\"],\n",
    "outputCol=\"features\")\n",
    "train = assembler.transform(latihan).select('Data', 'features')\n",
    "train.show(truncate = False, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a k-Means Clustering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model selesai dibuat!\n"
     ]
    }
   ],
   "source": [
    "# mendefinisikan algoritma clustering\n",
    "kmeans = KMeans(featuresCol = assembler.getOutputCol(), predictionCol=\"cluster\", k=3, maxIter=3, seed=0)\n",
    "\n",
    "# mentraining model dengan perintah \".fit()\"\n",
    "model = kmeans.fit(train)\n",
    "print(\"Model selesai dibuat!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the midpoint value of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centers: \n",
      "[5.6 7.6]\n",
      "[1.33333333 2.66666667]\n",
      "[9.  3.5]\n"
     ]
    }
   ],
   "source": [
    "centers = model.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|cluster|count|\n",
      "+-------+-----+\n",
      "|      0|    5|\n",
      "|      1|    3|\n",
      "|      2|    2|\n",
      "+-------+-----+\n",
      "\n",
      "+----+-------+\n",
      "|Data|cluster|\n",
      "+----+-------+\n",
      "|   1|      0|\n",
      "|   2|      0|\n",
      "|   3|      2|\n",
      "|   4|      1|\n",
      "|   5|      0|\n",
      "|   6|      1|\n",
      "|   7|      1|\n",
      "|   8|      2|\n",
      "|   9|      0|\n",
      "|  10|      0|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(train) # melakukan prediksi klaster\n",
    "prediction.groupBy(\"cluster\").count().orderBy(\"cluster\").show()\n",
    "prediction.select('Data', 'cluster').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-------+\n",
      "|Data|  features|cluster|\n",
      "+----+----------+-------+\n",
      "|   1| [5.0,8.0]|      1|\n",
      "|   2| [5.0,6.0]|      1|\n",
      "|   3| [9.0,3.0]|      3|\n",
      "|   4| [1.0,4.0]|      2|\n",
      "|   5| [7.0,8.0]|      1|\n",
      "|   6| [1.0,2.0]|      2|\n",
      "|   7| [2.0,2.0]|      2|\n",
      "|   8| [9.0,4.0]|      3|\n",
      "|   9|[5.0,10.0]|      1|\n",
      "|  10| [6.0,6.0]|      1|\n",
      "+----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "prediction.withColumn(\"cluster\",col(\"cluster\")+1).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
